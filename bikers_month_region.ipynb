{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import geoplot as gplt\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_cols = ['siteID', 'richting', 'type', 'van', 'tot', 'aantal']\n",
    "\n",
    "site_cols = ['siteID', 'sitenr', 'long', 'lat', 'naam', 'domein', 'wegnr', 'district', 'gemeente', 'interval', 'datum_van']\n",
    "\n",
    "sitesdf = pd.read_csv('data/bike_BEL/sites.csv', names=site_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5089/177028424.py:5: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_group = df_cat.groupby(['siteID','lat', 'long']).sum().reset_index()\n"
     ]
    }
   ],
   "source": [
    "df_cat = pd.merge(left = dfbikeBELjan, right = sitesdf[['siteID', 'lat', 'long']], left_on = 'siteID', right_on = 'siteID')\n",
    "\n",
    "#df_group = df_cat.groupby([['lat', 'long']], dropna=False).mean()\n",
    "\n",
    "df_group = df_cat.groupby(['siteID','lat', 'long']).sum().reset_index()\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5089/3689184235.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_group2 = df_cat2.groupby(['siteID','lat', 'long']).sum().reset_index()\n"
     ]
    }
   ],
   "source": [
    "#merge all the fietstelling palen into one dataframe and average the amount of cyclists per month per location\n",
    "# importing libraries\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "df_list = [] \n",
    "\n",
    "dir = 'data/bike_BEL/bikers_month/'\n",
    "\n",
    "for csv in os.listdir(dir):\n",
    "    csvpath = os.path.join(dir,csv)\n",
    "    df = pd.read_csv(csvpath, names = volume_cols)\n",
    "    df_list.append(df)\n",
    "\n",
    "combo_df = pd.concat(df_list, axis=0)\n",
    "\n",
    "df_cat2 = pd.merge(left = combo_df, right = sitesdf[['siteID', 'lat', 'long']], left_on = 'siteID', right_on = 'siteID')\n",
    "\n",
    "\n",
    "df_group2 = df_cat2.groupby(['siteID','lat', 'long']).sum().reset_index()\n",
    "\n",
    "df_group2['avg_month'] = df_group2['aantal'].apply(lambda x : x/(len(os.listdir(dir))))\n",
    "\n",
    "\n",
    "df_group2.to_csv('avg_cyclists_month_LatLong.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try  the same for  the netherlands, download data from https://opendata.cbs.nl/statline/portal.html?_la=en&_catalog=CBS&tableId=84710ENG&_theme=1172\n",
    "\n",
    "\n",
    "df_NL = pd.read_csv('data/bike_NL/84710ENG_UntypedDataSet_25032023_181036.csv', delimiter= ';')\n",
    "\n",
    "#Then clean the columns a bit, Trips_4, DistanceTravelled_5, TimeTravelled_6 are trips, kilometers and time in hours per year per province\n",
    "df_NL[['Trips_4', 'DistanceTravelled_5', 'TimeTravelled_6']] = df_NL[['Trips_4', 'DistanceTravelled_5', 'TimeTravelled_6']].replace('       .', 0).astype(float)\n",
    "\n",
    "\n",
    "#provinces_names_dict = {'PV20' : 'Groningen','PV21' : 'FryslÃ¢n', 'PV22' : 'Drenthe', 'PV23' : 'Overijssel', 'PV24': 'Flevoland', 'PV25':'Gelderland', 'PV26' : 'Utrecht', 'PV27': 'Noord-Holland', \n",
    "#                  'PV28': 'Zuid-Holland', 'PV29':'Zeeland',  'PV30': 'Noord-Brabant', 'PV31': 'Limburg'}\n",
    "\n",
    "#Change the characteristics column into their NUTS Level 2 designation\n",
    "provinces_NUTS = {'PV20' : 'NL11','PV21' : 'NL12', 'PV22' : 'NL13', 'PV23' : 'NL21', 'PV24': 'NL23','PV25':'NL22', 'PV26' : 'NL31', 'PV27': 'NL32', \n",
    "                  'PV28': 'NL33', 'PV29':'NL34',  'PV30': 'NL41', 'PV31': 'NL42'}\n",
    "\n",
    "df_NL['RegionCharacteristics'] = df_NL['RegionCharacteristics'].astype(str)\n",
    "df_NL['RegionCharacteristics'] = df_NL['RegionCharacteristics'].replace(provinces_NUTS, regex=True)\n",
    "df_NL= df_NL.rename(columns={'RegionCharacteristics':'NUTS_ID_LV2'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take an average of each province's trip numbers, kilometers, and hours, to get an average 'speed' per propvince\n",
    "#normalize this per province to get a sort of 'hinderance' factor\n",
    "df_NL_region_year = df_NL.groupby('NUTS_ID_LV2').agg(mean_tripnum = ('Trips_4', 'mean'), mean_km = ('DistanceTravelled_5', 'mean'), mean_hours = ('TimeTravelled_6', 'mean'))\n",
    "\n",
    "df_NL_region_year['avg_speed'] = df_NL_region_year[['mean_tripnum', 'mean_km', 'mean_hours']].apply(lambda x:  (x['mean_tripnum'] * x['mean_km']) / x['mean_hours'], axis=1)\n",
    "\n",
    "df_NL_region_year.reset_index(inplace=True)\n",
    "\n",
    "#apply Min-Max scaling to normalize the column   0 and 1\n",
    "df_NL_region_year['normalized_avg_speed'] = (df_NL_region_year['avg_speed'] - df_NL_region_year['avg_speed'].min()) / (df_NL_region_year['avg_speed'].max() - df_NL_region_year['avg_speed'].min())\n",
    "\n",
    "df_NL_region_year2 = df_NL_region_year.iloc[9:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datapackage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m data_url \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttps://datahub.io/core/geo-nuts-administrative-boundaries/datapackage.json\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[39m# to load Data Package into storage\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m package \u001b[39m=\u001b[39m datapackage\u001b[39m.\u001b[39mPackage(data_url)\n\u001b[1;32m      9\u001b[0m \u001b[39m# to load only tabular data\u001b[39;00m\n\u001b[1;32m     10\u001b[0m resources \u001b[39m=\u001b[39m package\u001b[39m.\u001b[39mresources\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datapackage' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the NUTS geojson\n",
    "\n",
    "nuts = gpd.read_file(\"data/NUTS_regions/NUTS_RG_01M_2021_4326.geojson\")\n",
    "\n",
    "#make for Benelux countries then NL\n",
    "nuts_benelux = nuts.loc[nuts[\"CNTR_CODE\"].isin([\"BE\",\"NL\",\"LU\"])]\n",
    "nuts_nl = nuts_benelux.loc[nuts_benelux[\"CNTR_CODE\"]==\"NL\"]\n",
    "\n",
    "#trim the nuts_nl ID column to its first 4 characters, these are its NUTS_LV2 designation\n",
    "nuts_nl['NUTS_ID_LV2'] = nuts_nl.apply(lambda row: row['NUTS_ID'][:4], axis=1)\n",
    "\n",
    "#try to make a new column for normalized average speed on the nuts_Nl map to use on interactive map, unfortunately makes NaNs, and doesnt bring the data correctly\n",
    "nuts_nl['norm_avg_speed'] = nuts_nl['NUTS_ID_LV2'].map(df_NL_region_year2.set_index('NUTS_ID_LV2')['avg_speed'])\n",
    "\n",
    "\n",
    "nuts_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datapackage import Package\n",
    "import pandas as pd\n",
    "\n",
    "#if the merge would have worked, could have plotted the merged dataframe with teh polygons showing the 'hinderance' factor\n",
    "data_url = 'https://datahub.io/core/geo-nuts-administrative-boundaries/datapackage.json'\n",
    "\n",
    "# to load Data Package into storage\n",
    "package = datapackage.Package(data_url)\n",
    "\n",
    "# to load only tabular data\n",
    "resources = package.resources\n",
    "for resource in resources:\n",
    "    if resource.tabular:\n",
    "        data = pd.read_csv(resource.descriptor['path'])\n",
    "        print (data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
